{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19760,
     "status": "ok",
     "timestamp": 1604697446940,
     "user": {
      "displayName": "Chi-Jen Chien",
      "photoUrl": "",
      "userId": "06662732836002486797"
     },
     "user_tz": 300
    },
    "id": "2_ddUciodeIK",
    "outputId": "ef7bf0d5-f08f-450d-87a4-1b6c8029775c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3146,
     "status": "ok",
     "timestamp": 1604697451752,
     "user": {
      "displayName": "Chi-Jen Chien",
      "photoUrl": "",
      "userId": "06662732836002486797"
     },
     "user_tz": 300
    },
    "id": "yFUlKfU7fbIt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import imageio\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image \n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 557,
     "status": "ok",
     "timestamp": 1604697458573,
     "user": {
      "displayName": "Chi-Jen Chien",
      "photoUrl": "",
      "userId": "06662732836002486797"
     },
     "user_tz": 300
    },
    "id": "voPinVYXfvah"
   },
   "outputs": [],
   "source": [
    "dog_path = \"gdrive/Shared drives/ECE765 Group Project/Dataset/val/dog/\"\n",
    "nondog_path = \"gdrive/Shared drives/ECE765 Group Project/Dataset/val/wild/\"\n",
    "train_path = \"gdrive/Shared drives/ECE765 Group Project/Dataset/Train_vae/\"\n",
    "val_path = \"gdrive/Shared drives/ECE765 Group Project/Dataset/Val_vae/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2967419,
     "status": "ok",
     "timestamp": 1604684986988,
     "user": {
      "displayName": "Chi-Jen Chien",
      "photoUrl": "",
      "userId": "06662732836002486797"
     },
     "user_tz": 300
    },
    "id": "8PtHtSTJlEQ8",
    "outputId": "3b545987-fb3a-4c70-89ea-7135444e2fd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4739\n",
      "9477\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#resize training data\n",
    "all_files = glob.glob(dog_path + \"*.jpg\")\n",
    "\n",
    "i = 0\n",
    "\n",
    "for filename in all_files:\n",
    "  i+=1\n",
    "  img = Image.open(filename)\n",
    "  new_image = img.resize((128, 128))\n",
    "  new_image.save(train_path+str(i)+\".png\")\n",
    "\n",
    "print(i)\n",
    "\n",
    "all_files = glob.glob(nondog_path + \"*.jpg\")\n",
    "\n",
    "for filename in all_files:\n",
    "  i+=1\n",
    "  img = Image.open(filename)\n",
    "  new_image = img.resize((128, 128))\n",
    "  new_image.save(train_path+str(i)+\".png\")\n",
    "\n",
    "print(i)\n",
    "\n",
    "#Train Dog: 4739\n",
    "#Train nonDog: 4738\n",
    "#Train Total: 9477\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 303205,
     "status": "ok",
     "timestamp": 1604697806644,
     "user": {
      "displayName": "Chi-Jen Chien",
      "photoUrl": "",
      "userId": "06662732836002486797"
     },
     "user_tz": 300
    },
    "id": "1WSWBmoARpBE",
    "outputId": "ed44d364-65a3-46cb-ce48-ba981ec1dcc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#resize testing data\n",
    "all_files = glob.glob(dog_path + \"*.jpg\")\n",
    "\n",
    "i = 0\n",
    "\n",
    "for filename in all_files:\n",
    "  i+=1\n",
    "  img = Image.open(filename)\n",
    "  new_image = img.resize((128, 128))\n",
    "  new_image.save(val_path+str(i)+\".png\")\n",
    "\n",
    "print(i)\n",
    "\n",
    "all_files = glob.glob(nondog_path + \"*.jpg\")\n",
    "\n",
    "for filename in all_files:\n",
    "  i+=1\n",
    "  img = Image.open(filename)\n",
    "  new_image = img.resize((128, 128))\n",
    "  new_image.save(val_path+str(i)+\".png\")\n",
    "\n",
    "print(i)\n",
    "\n",
    "#Test Dog: 500\n",
    "#Test nonDog: 500\n",
    "#Test Total: 1000\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77OtyhJBXrsn"
   },
   "outputs": [],
   "source": [
    "# Read Training data\n",
    "def read_training_data():\n",
    "  training_size = 9477\n",
    "  train_images = torch.zeros(training_size, 3, 128, 128, dtype=torch.uint8)\n",
    "  for n in range(1, training_size+1):\n",
    "    img_arr = imageio.imread(train_path+str(n)+\".png\")\n",
    "    img_t = torch.from_numpy(img_arr)\n",
    "    img_t = img_t.permute(2, 0, 1)\n",
    "    img_t = img_t[:3]\n",
    "    train_images[n-1] = img_t\n",
    "  train_images = train_images.float()\n",
    "  train_images /= 255.0\n",
    "  return train_images\n",
    "\n",
    "# Read Validation data\n",
    "def read_val_data():\n",
    "  val_size = 1000\n",
    "  val_images = torch.zeros(val_size, 3, 128, 128, dtype=torch.uint8)\n",
    "  for n in range(1,val_size+1):\n",
    "    img_arr = imageio.imread(val_path+str(n)+\".png\")\n",
    "    img_t = torch.from_numpy(img_arr)\n",
    "    img_t = img_t.permute(2, 0, 1)\n",
    "    img_t = img_t[:3]\n",
    "    val_images[n-1] = img_t\n",
    "  val_images = val_images.float()\n",
    "  val_images /= 255.0\n",
    "  return val_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V8aVqX8oaoiA"
   },
   "outputs": [],
   "source": [
    "#Zero-center and normalize the data\n",
    "\n",
    "def normalized_images(images):\n",
    "  n_channels = images.shape[1]\n",
    "  for c in range(n_channels):\n",
    "    mean = torch.mean(images[:, c])\n",
    "    std = torch.std(images[:, c])\n",
    "    images[:, c] = (images[:, c] - mean) / std\n",
    "  return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kCteESJXasQX"
   },
   "outputs": [],
   "source": [
    "#Build Training Dataset\n",
    "\n",
    "class TrainingDataset(Dataset):\n",
    "    def __init__(self):\n",
    "      self.preimages = read_training_data()\n",
    "      self.images = normalized_images(self.preimages)\n",
    "      self.labels = np.array([0] * 4739 + [1] * 4738)\n",
    "\n",
    "    def __len__(self):\n",
    "      return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "      img = self.images[idx]\n",
    "      label = self.labels[idx]\n",
    "      return img, label\n",
    "\n",
    "def trainDataset():\n",
    "  train_dataset = TrainingDataset()\n",
    "  return train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LidXKNl25H-6"
   },
   "outputs": [],
   "source": [
    "#Build Validation Dataset\n",
    "\n",
    "class ValDataset(Dataset):\n",
    "    def __init__(self):\n",
    "      self.preimages = read_val_data()\n",
    "      self.images = normalized_images(self.preimages)\n",
    "      self.labels = np.array([0] * 500 + [1] * 500)\n",
    "\n",
    "    def __len__(self):\n",
    "      return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "      img = self.images[idx]\n",
    "      label = self.labels[idx]\n",
    "      return img, label\n",
    "\n",
    "def valDataset():\n",
    "  val_dataset = ValDataset()\n",
    "  return val_dataset"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DataPrep_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
